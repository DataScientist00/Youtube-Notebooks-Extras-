{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2202206,"sourceType":"datasetVersion","datasetId":1322419}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](http://i.postimg.cc/BbD7fnL5/Screenshot-2025-11-04-201307.png)","metadata":{}},{"cell_type":"markdown","source":"# 1.IMPORTS\n","metadata":{}},{"cell_type":"code","source":"# ===============================\n# 1. IMPORTS\n# ===============================\nimport pandas as pd\nimport csv\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Subtract\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nimport matplotlib.pyplot as plt\n\nimport re\nimport nltk\nimport spacy\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom nltk.corpus import stopwords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:26.265254Z","iopub.execute_input":"2025-11-07T10:10:26.265999Z","iopub.status.idle":"2025-11-07T10:10:26.271052Z","shell.execute_reply.started":"2025-11-07T10:10:26.265971Z","shell.execute_reply":"2025-11-07T10:10:26.270177Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Converting Text file to csv","metadata":{}},{"cell_type":"code","source":"# Read data from text\nwith open('/kaggle/input/mit-plagairism-detection-dataset/train_snli.txt') as file:\n    data = file.readlines()\n    \n# prepare csv file\nwith open('data.csv', 'w', newline= '') as csvfile:\n    filenames = ['source_txt', 'plagiarism_txt', 'label']\n    writer = csv.DictWriter(csvfile, fieldnames=filenames)\n    \n    writer.writeheader()\n    for line in tqdm(data):\n        parts = line.strip().split('\\t')\n        source_txt = parts[0]\n        plagiarishm_txt = parts[1]\n        label = int(parts[2])\n        \n        writer.writerow({\n            'source_txt' : source_txt,\n            'plagiarism_txt' : plagiarishm_txt,\n            'label' : label\n        })\nprint('CSV file created successfully...')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:26.272211Z","iopub.execute_input":"2025-11-07T10:10:26.272420Z","iopub.status.idle":"2025-11-07T10:10:28.323211Z","shell.execute_reply.started":"2025-11-07T10:10:26.272404Z","shell.execute_reply":"2025-11-07T10:10:28.322548Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/367373 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8be6a10e16471fb578704a6d5e37c4"}},"metadata":{}},{"name":"stdout","text":"CSV file created successfully...\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# 2. LOAD DATA\n","metadata":{}},{"cell_type":"code","source":"\n# Replace with your dataset path\ndf = pd.read_csv(\"data.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:28.324174Z","iopub.execute_input":"2025-11-07T10:10:28.324465Z","iopub.status.idle":"2025-11-07T10:10:28.979486Z","shell.execute_reply.started":"2025-11-07T10:10:28.324437Z","shell.execute_reply":"2025-11-07T10:10:28.978730Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                          source_txt  \\\n0  A person on a horse jumps over a broken down a...   \n1  A person on a horse jumps over a broken down a...   \n2              Children smiling and waving at camera   \n3              Children smiling and waving at camera   \n4  A boy is jumping on skateboard in the middle o...   \n\n                                  plagiarism_txt  label  \n0  A person is at a diner, ordering an omelette.      0  \n1              A person is outdoors, on a horse.      1  \n2                     There are children present      1  \n3                          The kids are frowning      0  \n4              The boy skates down the sidewalk.      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_txt</th>\n      <th>plagiarism_txt</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A person on a horse jumps over a broken down a...</td>\n      <td>A person is at a diner, ordering an omelette.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A person on a horse jumps over a broken down a...</td>\n      <td>A person is outdoors, on a horse.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Children smiling and waving at camera</td>\n      <td>There are children present</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Children smiling and waving at camera</td>\n      <td>The kids are frowning</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A boy is jumping on skateboard in the middle o...</td>\n      <td>The boy skates down the sidewalk.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.duplicated().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:28.980303Z","iopub.execute_input":"2025-11-07T10:10:28.980622Z","iopub.status.idle":"2025-11-07T10:10:29.148802Z","shell.execute_reply.started":"2025-11-07T10:10:28.980587Z","shell.execute_reply":"2025-11-07T10:10:29.148190Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"454"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:29.150119Z","iopub.execute_input":"2025-11-07T10:10:29.150331Z","iopub.status.idle":"2025-11-07T10:10:29.332428Z","shell.execute_reply.started":"2025-11-07T10:10:29.150315Z","shell.execute_reply":"2025-11-07T10:10:29.331558Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 3. BASIC CLEANING FUNCTION\n","metadata":{}},{"cell_type":"code","source":"\nimport re, string\n\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\n\", \" \", text) #Replace newlines with spaces\n    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) #Remove punctuation\n    return text\n\n\n# Apply cleaning\ndf[\"source_clean\"] = df[\"source_txt\"].astype(str).apply(clean_text)\ndf[\"plag_clean\"] = df[\"plagiarism_txt\"].astype(str).apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:29.333107Z","iopub.execute_input":"2025-11-07T10:10:29.333367Z","iopub.status.idle":"2025-11-07T10:10:32.082112Z","shell.execute_reply.started":"2025-11-07T10:10:29.333344Z","shell.execute_reply":"2025-11-07T10:10:32.081541Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# 4. TOKENIZATION\n","metadata":{}},{"cell_type":"code","source":"\nsource = df['source_clean'].tolist()\nplag = df['plag_clean'].tolist()\nlabels = df['label'].values\n\n\ntokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(source + plag)\n\n\nsource_seq = tokenizer.texts_to_sequences(source)\nplag_seq = tokenizer.texts_to_sequences(plag)\n\n\nmax_len = 50\nsource_pad = pad_sequences(source_seq, maxlen=max_len)\nplag_pad = pad_sequences(plag_seq, maxlen=max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:32.082913Z","iopub.execute_input":"2025-11-07T10:10:32.083143Z","iopub.status.idle":"2025-11-07T10:10:47.042182Z","shell.execute_reply.started":"2025-11-07T10:10:32.083126Z","shell.execute_reply":"2025-11-07T10:10:47.041575Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# 5. SPLIT DATA\n","metadata":{}},{"cell_type":"code","source":"\nX_train_src, X_test_src, X_train_plag, X_test_plag, y_train, y_test = train_test_split(\nsource_pad, plag_pad, labels, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:47.042933Z","iopub.execute_input":"2025-11-07T10:10:47.043178Z","iopub.status.idle":"2025-11-07T10:10:47.156954Z","shell.execute_reply.started":"2025-11-07T10:10:47.043152Z","shell.execute_reply":"2025-11-07T10:10:47.156359Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# 6. BUILD LSTM MODEL\n","metadata":{}},{"cell_type":"code","source":"#Siamese LSTM network\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 128\nlstm_dim = 64\n\n\ninput_a = Input(shape=(max_len,))\ninput_b = Input(shape=(max_len,))\n\n\nembedding = Embedding(vocab_size, embedding_dim, input_length=max_len)\nlstm = LSTM(lstm_dim)\n\n\nencoded_a = lstm(embedding(input_a))\nencoded_b = lstm(embedding(input_b))\n\n# The idea: if the texts are similar, the difference vector should be small.\nmerged = Subtract()([encoded_a, encoded_b])\nmerged = Dense(64, activation=\"relu\")(merged)\nmerged = Dropout(0.5)(merged)\nout = Dense(1, activation=\"sigmoid\")(merged)\n\n\nmodel = Model(inputs=[input_a, input_b], outputs=out)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:47.157745Z","iopub.execute_input":"2025-11-07T10:10:47.158011Z","iopub.status.idle":"2025-11-07T10:10:48.798435Z","shell.execute_reply.started":"2025-11-07T10:10:47.157982Z","shell.execute_reply":"2025-11-07T10:10:48.797739Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1762510247.328969      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚  \u001b[38;5;34m3,874,432\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m49,408\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ subtract (\u001b[38;5;33mSubtract\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       â”‚\nâ”‚                     â”‚                   â”‚            â”‚ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m4,160\u001b[0m â”‚ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m65\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,874,432</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       â”‚\nâ”‚                     â”‚                   â”‚            â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,928,065\u001b[0m (14.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,928,065</span> (14.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,928,065\u001b[0m (14.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,928,065</span> (14.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nes = EarlyStopping(\n    monitor='val_loss',\n    patience=2,\n    restore_best_weights=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:48.799418Z","iopub.execute_input":"2025-11-07T10:10:48.799695Z","iopub.status.idle":"2025-11-07T10:10:48.804885Z","shell.execute_reply.started":"2025-11-07T10:10:48.799678Z","shell.execute_reply":"2025-11-07T10:10:48.804333Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# 7. TRAIN MODEL\n","metadata":{}},{"cell_type":"code","source":"\nhistory = model.fit(\n    [X_train_src, X_train_plag],\n    y_train,\n    validation_split=0.2,\n    epochs=10,\n    batch_size=32,\n    callbacks=[es],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:10:48.806767Z","iopub.execute_input":"2025-11-07T10:10:48.807370Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1762510253.457593     104 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1905/7339\u001b[0m \u001b[32mâ”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m52s\u001b[0m 10ms/step - accuracy: 0.6889 - loss: 0.5644","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# 8. EVALUATION\n","metadata":{}},{"cell_type":"code","source":"\npred = model.predict([X_test_src, X_test_plag])\npred_label = (pred > 0.5).astype(int)\n\n\nprint(\"Accuracy:\", accuracy_score(y_test, pred_label))\nprint(classification_report(y_test, pred_label))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. PLOT TRAINING CURVES\n","metadata":{}},{"cell_type":"code","source":"\nplt.plot(history.history['accuracy'], label='train_acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.title('Accuracy over epochs')\nplt.legend()\nplt.show()\n\n\nplt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.title('Loss over epochs')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. SAMPLE PREDICTION\n","metadata":{}},{"cell_type":"code","source":"\nidx = 0\nsrc = X_test_src[idx:idx+1]\nplg = X_test_plag[idx:idx+1]\nprint(\"Pred:\", model.predict([src, plg])[0][0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing Model on User Inputs","metadata":{}},{"cell_type":"code","source":"def predict_pair(source_text, plag_text, tokenizer, max_len):\n    # Convert to sequences\n    src_seq = tokenizer.texts_to_sequences([source_text])\n    plg_seq = tokenizer.texts_to_sequences([plag_text])\n    \n    # Pad\n    src_pad = pad_sequences(src_seq, maxlen=max_len)\n    plg_pad = pad_sequences(plg_seq, maxlen=max_len)\n\n    # Predict\n    pred = model.predict([src_pad, plg_pad])[0][0]\n\n    # Show result\n    print(\"Prediction score:\", pred)\n    if pred > 0.5:\n        print(\"âœ… Likely PLAGIARIZED\")\n    else:\n        print(\"âŒ Likely NOT plagiarized\")\n\n    return pred\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src = \"A woman is standing outside wearing glasses.\"\nplg = \"A woman wearing glasses is outdoors.\"\n\npredict_pair(src, plg, tokenizer, max_len)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src = \"Two kids are sleeping on a bench.\"\nplg = \"A car is driving on the road.\"\n\npredict_pair(src, plg, tokenizer, max_len)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<span style=\"color: white; background-color: red; padding: 10px 20px; border-radius: 10px; font-size: 36px; font-weight: bold;\">Smash That Upvote !! Thanks ! ğŸš€ğŸ˜ƒ</span>\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}